# -*- coding: utf-8 -*-
"""ML_Assignment.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_dIa-uNASRVl0kiXNbBqZ7MrV6KsEdoC

**Importing Libraries**
"""

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

import tensorflow as tf
from tensorflow.keras import datasets, layers, models, callbacks
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import EarlyStopping

from sklearn.metrics import classification_report, confusion_matrix

"""**Exploring the Dataset**"""

#Data Loading
(X_train, y_train), (X_test, y_test) = cifar10.load_data()

#Examining the shape
print(f"X_train shape: {X_train.shape}")
print(f"y_train shape: {y_train.shape}")
print(f"X_test shape: {X_test.shape}")
print(f"y_test shape: {y_test.shape}")

# Define the labels of the dataset
labels = ['airplane', 'automobile', 'bird', 'cat', 'deer',
          'dog', 'frog', 'horse', 'ship', 'truck']

# Define the dimensions of the plot grid
W_grid = 10
L_grid = 10

#Subplot
fig, axes = plt.subplots(L_grid, W_grid, figsize = (17,17))
axes = axes.ravel() # flaten the 15 x 15 matrix into 225 array

n_train = len(X_train) # get the length of the train dataset

# Select a random number from 0 to n_train
for i in np.arange(0, W_grid * L_grid): # create evenly spaces variables

    # Select a random number
    index = np.random.randint(0, n_train)
    # read and display an image with the selected index
    axes[i].imshow(X_train[index,1:])
    label_index = int(y_train[index])
    axes[i].axis('off')

plt.subplots_adjust(hspace=0.4)

classes_name = ['Airplane', 'Automobile', 'Bird', 'Cat', 'Deer', 'Dog', 'Frog', 'Horse', 'Ship', 'Truck']

classes, counts = np.unique(y_train, return_counts=True)
plt.barh(classes_name, counts)
plt.title('Class distribution in training set')

classes, counts = np.unique(y_test, return_counts=True)
plt.barh(classes_name, counts)
plt.title('Class distribution in testing set')

"""**Pre-Training using ResNet50**"""

#Splitting the trainfull set into train and validation set
X_train, X_valid = X_trainfull[:-5_000], X_trainfull[-5_000:]
y_train, y_valid = y_trainfull[:-5_000], y_trainfull[-5_000:]

label_names = ["airplane", "automobile", "bird", "cat", "deer", "dog", "frog", "horse", "ship", "truck"]

#Data Preprocessing function
def preprocess_image_input(input_images):
  input_images = input_images.astype('float32')
  output_ims = tf.keras.applications.resnet50.preprocess_input(input_images)
  return output_ims

# Applying the preprocessing function
train_X = preprocess_image_input(X_train)
valid_X = preprocess_image_input(X_valid)

# Building the model
from tensorflow.keras import regularizers

# Function to define and compile the model with fine-tuning options
def define_compile_model(fine_tune_layers=None):
    inputs = tf.keras.layers.Input(shape=(32, 32, 3))

    # Upsample input images to (224, 224, 3)
    resize = tf.keras.layers.UpSampling2D(size=(7, 7))(inputs)

    # Load ResNet50 model with pre-trained weights
    resnet = tf.keras.applications.ResNet50(
        input_shape=(224, 224, 3),
        include_top=False,
        weights='imagenet'
    )

    # Freeze or unfreeze layers based on fine_tune_layers argument
    if fine_tune_layers is not None:
        for layer in resnet.layers[:-fine_tune_layers]:
            layer.trainable = False
    else:
        for layer in resnet.layers:
            layer.trainable = False

    # Connect ResNet50 model
    resnet_feature_extractor = resnet(resize)

    # Classifier layers with dropout
    x = tf.keras.layers.GlobalAveragePooling2D()(resnet_feature_extractor)
    x = tf.keras.layers.Flatten()(x)
    x = tf.keras.layers.Dense(256, activation="relu", kernel_regularizer=regularizers.l2(0.01))(x)
    x = tf.keras.layers.Dropout(0.6)(x)  # Increased dropout rate
    x = tf.keras.layers.Dense(128, activation="relu", kernel_regularizer=regularizers.l2(0.01))(x)
    x = tf.keras.layers.Dropout(0.6)(x)  # Increased dropout rate
    x = tf.keras.layers.Dense(10, activation="softmax", name="classification")(x)


    # Final model
    model = tf.keras.Model(inputs=inputs, outputs=x)

    # Compile the model
    model.compile(optimizer='SGD',
                  loss='sparse_categorical_crossentropy',
                  metrics=['accuracy'])

    return model

# Create and compile the model with fine-tuning of the last 50 layers
model = define_compile_model(fine_tune_layers=100)

# Display the model summary
model.summary()

keras.backend.clear_session()

# Define early stopping callback
early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)

# Train the model with early stopping
EPOCHS = 5
history = model.fit(train_X, y_train, epochs=EPOCHS, validation_data=(valid_X, y_valid), batch_size=64, callbacks=[early_stopping])

test_X = preprocess_image_input(X_test)
test_loss, test_accuracy = model.evaluate(test_X, y_test)
print(f"\nTest Loss: {test_loss:.4f}")
print(f"Test Accuracy: {test_accuracy:.4f}")

# Visualize training and validation curves
plt.figure(figsize=[10, 5])
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()

plt.show()

# Predictions on the test set
y_pred = np.argmax(model.predict(test_X), axis=1)

# Classification Report
class_report = classification_report(y_test, y_pred, target_names=label_names)
print("Classification Report:")
print(class_report)

# Confusion Matrix
conf_matrix = confusion_matrix(y_test, y_pred)
print("\nConfusion Matrix:")
print(conf_matrix)

# Plot Confusion Matrix as Heatmap
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=label_names, yticklabels=label_names)
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

# Function to display images along with true and predicted labels
def plot_images(images, true_labels, pred_labels, class_names):
    plt.figure(figsize=(12, 6))
    for i in range(10):
        plt.subplot(2, 5, i + 1)
        plt.imshow(images[i])
        plt.title(f"True: {class_names[true_labels[i][0]]}\nPred: {class_names[pred_labels[i]]}")
        plt.axis('off')
    plt.show()

# Choose 10 random indices from the test set
random_indices = np.random.choice(len(X_test), size=10, replace=False)

# Select the corresponding images, true labels, and make predictions
sample_images = X_test[random_indices]
true_labels = y_test[random_indices]
predicted_labels = np.argmax(model.predict(preprocess_image_input(sample_images)), axis=1)

# Plot the images with true and predicted labels
plot_images(sample_images, true_labels, predicted_labels, label_names)

"""**Scratch Model using CNN**"""

# Loading the dataset
(X_trainfull, y_trainfull), (X_test, y_test) = keras.datasets.cifar10.load_data()


# Normalize pixel values to be between 0 and 1
X_trainfull= X_trainfull / 255.0
X_test = X_test / 255.0


# One-hot encode labels
y_trainfull = to_categorical(y_trainfull, 10)
y_test = to_categorical(y_test, 10)

# Split the data into training and validation sets
val_split = 0.1
val_size = int(len(X_trainfull) * val_split)

X_train, X_val = X_trainfull[:-val_size], X_trainfull[-val_size:]
y_train, y_val = y_trainfull[:-val_size], y_trainfull[-val_size:]

#Define Model
model = keras.Sequential()

model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))
model.add(layers.MaxPooling2D((2, 2)))

model.add(layers.Conv2D(64, (3, 3), activation='relu'))
model.add(layers.MaxPooling2D((2, 2)))

model.add(layers.Conv2D(128, (3, 3), activation='relu'))
model.add(layers.MaxPooling2D((2, 2)))

model.add(layers.Flatten())

model.add(layers.Dense(256, activation='relu'))
model.add(Dropout(0.5))

model.add(layers.Dense(128, activation='relu'))
model.add(Dropout(0.5))

model.add(layers.Dense(10, activation='softmax'))

# Compile the model
model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001),
              loss='categorical_crossentropy',
              metrics=['accuracy'])

# Display the model summary
model.summary()

# Adding EarlyStopping callback
early_stopping = keras.callbacks.EarlyStopping(
    monitor='val_loss',  # Monitor validation loss
    patience=5,           # Number of epochs with no improvement after which training will be stopped
    restore_best_weights=True  # Restore model weights from the epoch with the best value of the monitored quantity
)

# Training the model with data augmentation
history = model.fit(X_train, y_train,
                    epochs=100,
                    validation_data=(X_val, y_val),
                    callbacks=[early_stopping])

# Evaluate the model on the test set
test_loss, test_accuracy = model.evaluate(X_test, y_test)
print(f"\nTest Loss: {test_loss:.4f}")
print(f"Test Accuracy: {test_accuracy:.4f}")

# Visualize training and validation curves
plt.figure(figsize=[10, 5])
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()

plt.show()

# Get class names
class_names = ["airplane", "automobile", "bird", "cat", "deer", "dog", "frog", "horse", "ship", "truck"]
# Make predictions on the test set
y_pred = model.predict(X_test)
y_pred_classes = np.argmax(y_pred, axis=1)
y_true_classes = np.argmax(y_test, axis=1)

# Classification Report
print("\nClassification Report:\n", classification_report(y_true_classes, y_pred_classes))

# Confusion Matrix
conf_mat = confusion_matrix(y_true_classes, y_pred_classes)

# Print Confusion Matrix
print("\nConfusion Matrix:\n", conf_mat)

# Plot Confusion Matrix as Heatmap
plt.figure(figsize=(10, 8))
sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)
plt.title('Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('True')
plt.show()